{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b3f7a7",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#tl;dr\" data-toc-modified-id=\"tl;dr-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>tl;dr</a></span></li><li><span><a href=\"#setup\" data-toc-modified-id=\"setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>setup</a></span></li><li><span><a href=\"#data\" data-toc-modified-id=\"data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd42ba",
   "metadata": {},
   "source": [
    "# tl;dr\n",
    "\n",
    "in this notebook i prepare the data for the wildfire spread prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74538cb2",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "22f5bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import warnings\n",
    "from io import BytesIO\n",
    "import psutil\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp \n",
    "import tqdm\n",
    "from folium.plugins import HeatMap\n",
    "from IPython.display import display\n",
    "from scipy.interpolate import griddata\n",
    "from selenium import webdriver\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='u22', release='6.2.0-36-generic', version='#37~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  9 15:34:04 UTC 2', machine='x86_64')\n",
      "Cores:  16\n",
      "Memory:  15.54 GB\n",
      "\n",
      "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "sys.version_info(major=3, minor=10, micro=12, releaselevel='final', serial=0)\n",
      "\n",
      "2.0.0+cu117\n",
      "11.7\n",
      "8500\n",
      "NVIDIA GeForce GTX 1660 Ti\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.uname())\n",
    "print(\"Cores: \", os.cpu_count())\n",
    "print(\"Memory: \", round(psutil.virtual_memory().total / 1024 / 1024 / 1024, 2), \"GB\")\n",
    "print()\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "print()\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "275e636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    \"\"\"\n",
    "    Convert size of objects in memory\n",
    "    \"\"\"\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"{:>6.1f} {}{}\".format(num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"{:.1f} {}{}\".format(num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e1fd078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size'       : 9,\n",
    "    'figure.figsize'  : (3.5, 2.8),\n",
    "    'figure.dpi'      : 300,\n",
    "    'savefig.dpi'     : 300,\n",
    "    'text.usetex'     : True,\n",
    "    'font.family'     : 'serif',\n",
    "    'font.serif'      : ['Times New Roman'],\n",
    "    'axes.labelsize'  : 9,\n",
    "    'axes.titlesize'  : 9,\n",
    "    'xtick.labelsize' : 8,\n",
    "    'ytick.labelsize' : 8,\n",
    "    'legend.fontsize' : 8,\n",
    "    'lines.linewidth' : 1,\n",
    "    'axes.linewidth'  : 1,\n",
    "    'grid.linestyle'  : '--',\n",
    "    'grid.linewidth'  : 0.5,\n",
    "    'grid.alpha'      : 0.8,\n",
    "})\n",
    "\n",
    "sns.set_context(\n",
    "    \"paper\", \n",
    "    rc={\n",
    "        \"font.size\"      : 9,\n",
    "        \"axes.titlesize\" : 9,\n",
    "        \"axes.labelsize\" : 9, \n",
    "        'xtick.labelsize': 8,\n",
    "        'ytick.labelsize': 8\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a6b692b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"wildfire_spread\"\n",
    "folder_path = f\"../data/08_reporting/{experiment_name}\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "golden_ratio = (np.sqrt(5) - 1) / 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f99e0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAZIL_EXTENT = [-74, -34, -34, 6]\n",
    "SAO_PAULO_EXTENT = [-53, -44, -25, -20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62520dc",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b6ed7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LAT = 32.99499999641088\n",
    "MIN_LAT = -55.98500000358912\n",
    "MAX_LON = -33.009801806103724\n",
    "MIN_LON = -119.98980180610373\n",
    "\n",
    "MAX_LAT = BRAZIL_EXTENT[3]\n",
    "MIN_LAT = BRAZIL_EXTENT[2]\n",
    "MAX_LON = BRAZIL_EXTENT[1]\n",
    "MIN_LON = BRAZIL_EXTENT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c80c3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_tensor_layer_feature(data, column_name:str):\n",
    "    \"\"\"\n",
    "    Convert data to tensor layer feature\n",
    "    \"\"\"\n",
    "    # LAT_LON_SHAPE = (3000, 3000)\n",
    "\n",
    "    MAX_LAT = 32.99499999641088\n",
    "    MIN_LAT = -55.98500000358912\n",
    "    MAX_LON = -33.009801806103724\n",
    "    MIN_LON = -119.98980180610373\n",
    "\n",
    "    MAX_LAT = BRAZIL_EXTENT[3]\n",
    "    MIN_LAT = BRAZIL_EXTENT[2]\n",
    "    MAX_LON = BRAZIL_EXTENT[1]\n",
    "    MIN_LON = BRAZIL_EXTENT[0]\n",
    "\n",
    "    fig = plt.figure(figsize=(1, 1))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    ax.set_extent([MIN_LON, MAX_LON, MIN_LAT, MAX_LAT], crs=ccrs.PlateCarree(),)\n",
    "\n",
    "    try:\n",
    "        ax.imshow(\n",
    "            np.flipud(data.variables[column_name][:].data[0]),\n",
    "            origin=\"upper\",\n",
    "            extent=[MIN_LON, MAX_LON, MIN_LAT, MAX_LAT],\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=\"gray\",\n",
    "        )\n",
    "    except:\n",
    "        ax.imshow(\n",
    "            data.variables[column_name][:].data[0],\n",
    "            origin=\"upper\",\n",
    "            extent=[MIN_LON, MAX_LON, MIN_LAT, MAX_LAT],\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=\"gray\",\n",
    "        )\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    # gray_data = np.dot(data[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    # gray_data_normalized = gray_data / 255.0\n",
    "    sum_channel_data = np.sum(data, axis=2)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return sum_channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7f60d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_tensor_layer_target(longitude, latitude):\n",
    "    \"\"\"\n",
    "    Convert data to tensor layer target\n",
    "    \"\"\"\n",
    "    # LAT_LON_SHAPE = (2000, 2000)\n",
    "\n",
    "    MAX_LAT = 32.99499999641088\n",
    "    MIN_LAT = -55.98500000358912\n",
    "    MAX_LON = -33.009801806103724\n",
    "    MIN_LON = -119.98980180610373\n",
    "\n",
    "    MAX_LAT = BRAZIL_EXTENT[3]\n",
    "    MIN_LAT = BRAZIL_EXTENT[2]\n",
    "    MAX_LON = BRAZIL_EXTENT[1]\n",
    "    MIN_LON = BRAZIL_EXTENT[0]\n",
    "\n",
    "    # fig = plt.figure(figsize=(3, 3))\n",
    "    # ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    # ax.set_extent([MIN_LON, MAX_LON, MIN_LAT, MAX_LAT], crs=ccrs.PlateCarree(),)\n",
    "\n",
    "    # ax.add_feature(cfeature.BORDERS, linewidth=0.05, edgecolor=\"white\", zorder=2)\n",
    "    # ax.add_feature(cfeature.COASTLINE, linewidth=0.05, edgecolor=\"white\", zorder=2)\n",
    "    \n",
    "    _hist = np.histogram2d(\n",
    "        longitude, latitude, bins=300, range=[[MIN_LON, MAX_LON], [MIN_LAT, MAX_LAT]]\n",
    "    )\n",
    "    _hist_plot = _hist[0] \n",
    "    _hist_plot = np.where(_hist_plot > 0, 1, 0)\n",
    "\n",
    "    # ax.imshow(\n",
    "    #     np.flipud(_hist_plot.T),\n",
    "    #     origin=\"upper\",\n",
    "    #     extent=[MIN_LON, MAX_LON, MIN_LAT, MAX_LAT],\n",
    "    #     transform=ccrs.PlateCarree(),\n",
    "    # )\n",
    "    # ax.set_axis_off()\n",
    "\n",
    "    # data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    # data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    # # gray_data = np.dot(data[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    # # gray_data_normalized = gray_data / 255.0\n",
    "    # sum_channel_data = np.sum(data, axis=2)\n",
    "\n",
    "    return np.flipud(_hist_plot.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6a033920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 80/123 [00:00<00:00, 164.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 97/123 [00:05<00:02, 12.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 104/123 [00:08<00:02,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 108/123 [00:09<00:02,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 111/123 [00:10<00:01,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 113/123 [00:11<00:01,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n",
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 115/123 [00:12<00:01,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "num_dias_sem_chuva (300, 300)\n",
      "precipitacao (300, 300)\n",
      "temperatura (300, 300)\n",
      "umidade (300, 300)\n",
      "(5, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:12<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fire occurence (300, 300)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LAT_LON_SHAPE = (2000, 2000)\n",
    "# # TENSOR = np.empty((0, 6, LAT_LON_SHAPE[0], LAT_LON_SHAPE[1]))\n",
    "# TENSOR = np.empty((0, 5, LAT_LON_SHAPE[0], LAT_LON_SHAPE[1]))\n",
    "TENSOR_TIMESTAMPS = list()\n",
    "\n",
    "# for _dt in tqdm.tqdm(pd.date_range(\"2023-08-01\", \"2023-12-01\")):\n",
    "for _dt in tqdm.tqdm(pd.date_range(\"2023-08-01\", \"2023-12-01\")):\n",
    "    try:\n",
    "        print()\n",
    "        # fire occurence\n",
    "        _dataset = pd.read_csv(f\"../data/01_raw/inpe_queimadas/focos/focos_diario_br_{_dt.strftime('%Y%m%d')}.csv\")\n",
    "        # if _dataset.query(\"risco_fogo > 0\").shape[0] > 0:\n",
    "        if _dataset.shape[0] > 0:\n",
    "            _tensor = list()\n",
    "\n",
    "            # _dataset = _dataset.query(\"risco_fogo >= 0\").copy()\n",
    "            data = convert_data_to_tensor_layer_target(_dataset[\"lon\"], _dataset[\"lat\"])\n",
    "            print(\"fire occurence\", data.shape)\n",
    "            _tensor.append(data)\n",
    "\n",
    "            # loading num_dias_sem_chuva\n",
    "            _file_path = f\"../data/01_raw/inpe_queimadas/numero_dias_sem_chuva/INPE_FireRiskModel_2.2_NDWR_{_dt.strftime('%Y%m%d')}.nc\"\n",
    "            _dataset = nc.Dataset(_file_path)\n",
    "            data = convert_data_to_tensor_layer_feature(_dataset, \"ndsc120\")\n",
    "            print(\"num_dias_sem_chuva\", data.shape)\n",
    "            _tensor.append(data)\n",
    "\n",
    "            # loading precipitacao\n",
    "            _file_path = f\"../data/01_raw/inpe_queimadas/precipitacao/INPE_FireRiskModel_2.2_Precipitation_{_dt.strftime('%Y%m%d')}.nc\"\n",
    "            _dataset = nc.Dataset(_file_path)\n",
    "            data = convert_data_to_tensor_layer_feature(_dataset, \"prec\")\n",
    "            print(\"precipitacao\", data.shape)\n",
    "            _tensor.append(data)\n",
    "\n",
    "            # loading temperatura\n",
    "            _file_path = f\"../data/01_raw/inpe_queimadas/temperatura/INPE_FireRiskModel_2.2_Temperature_{_dt.strftime('%Y%m%d')}.nc\"\n",
    "            _dataset = nc.Dataset(_file_path)\n",
    "            data = convert_data_to_tensor_layer_feature(_dataset, \"temp2m\")\n",
    "            print(\"temperatura\", data.shape)\n",
    "            _tensor.append(data)\n",
    "\n",
    "            # loading umidade\n",
    "            _file_path = f\"../data/01_raw/inpe_queimadas/umidade_relativa/INPE_FireRiskModel_2.2_RelativeHumidity_{_dt.strftime('%Y%m%d')}.nc\"\n",
    "            _dataset = nc.Dataset(_file_path)\n",
    "            data = convert_data_to_tensor_layer_feature(_dataset, \"rh2m\")\n",
    "            print(\"umidade\", data.shape)\n",
    "            _tensor.append(data)\n",
    "\n",
    "            # # loading risco de fogo\n",
    "            # _file_path = f\"../data/01_raw/inpe_queimadas/risco_fogo/INPE_FireRiskModel_2.2_FireRisk_{_dt.strftime('%Y%m%d')}.nc\"\n",
    "            # _dataset = nc.Dataset(_file_path)\n",
    "            # data = convert_data_to_tensor_layer_feature(_dataset, \"rf\")\n",
    "            # print(\"risco de fogo\", data.shape)\n",
    "            # _tensor.append(data)\n",
    "\n",
    "            # TENSOR = np.append(TENSOR, np.array([_tensor]), axis=0)\n",
    "            # TENSOR_TIMESTAMPS.append(_dt.strftime(\"%Y-%m-%d\"))\n",
    "            print(np.array(_tensor).shape)\n",
    "\n",
    "            # save as compressed npz\n",
    "            np.savez_compressed(\n",
    "                f\"../data/02_intermediate/wildfire_spread/{_dt.strftime('%Y%m%d')}.npz\",\n",
    "                tensor=np.array(_tensor),\n",
    "                timestamps=_dt.strftime(\"%Y-%m-%d\"),\n",
    "            )\n",
    "            \n",
    "            # clean temporary variables and memory\n",
    "            del _tensor\n",
    "            del data\n",
    "            del _dataset\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-19\n",
      "2023-10-20\n",
      "2023-10-21\n",
      "2023-10-22\n",
      "2023-10-23\n",
      "2023-10-24\n",
      "2023-10-25\n",
      "2023-10-26\n",
      "2023-10-27\n",
      "2023-10-28\n",
      "2023-10-29\n",
      "2023-10-30\n",
      "2023-10-31\n",
      "2023-11-01\n",
      "2023-11-02\n",
      "2023-11-03\n",
      "2023-11-04\n",
      "2023-11-05\n",
      "2023-11-06\n",
      "2023-11-07\n",
      "2023-11-08\n",
      "2023-11-09\n",
      "2023-11-10\n",
      "2023-11-11\n",
      "2023-11-12\n",
      "2023-11-13\n",
      "2023-11-14\n",
      "2023-11-15\n",
      "2023-11-16\n",
      "2023-11-17\n",
      "2023-11-18\n",
      "2023-11-19\n",
      "2023-11-20\n",
      "2023-11-21\n",
      "2023-11-22\n",
      "2023-11-23\n",
      "2023-11-24\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.empty((0, 5, 300, 300), dtype=torch.float16)\n",
    "\n",
    "for _dt in pd.date_range(\"2023-08-01\", \"2023-12-01\", freq=\"D\"):\n",
    "    try:\n",
    "        _data = np.load(\n",
    "            f\"../data/02_intermediate/wildfire_spread/{_dt.strftime('%Y%m%d')}.npz\",\n",
    "        )\n",
    "        print(_dt.strftime(\"%Y-%m-%d\"))\n",
    "        _timestamp = _data[\"timestamps\"]\n",
    "        _tensor = _data[\"tensor\"].astype(np.float16)\n",
    "        _tensor = torch.from_numpy(_tensor)\n",
    "        _tensor = _tensor.unsqueeze(0)\n",
    "        TENSOR = torch.cat((TENSOR, _tensor), dim=0)\n",
    "        del _tensor\n",
    "        del _data\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(TENSOR, f\"../data/02_intermediate/wildfire_spread/wildfire_spread_tensor.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      _dataset:    3.6 MiB\n",
      "                          data:  703.2 KiB\n",
      "                          _iii:    3.4 KiB\n",
      "                          _i13:    3.4 KiB\n",
      "                           _i8:    1.5 KiB\n",
      "                          _i11:    1.5 KiB\n",
      "                          _i12:    1.1 KiB\n",
      "                       HeatMap:    1.0 KiB\n",
      "                 ParameterGrid:    1.0 KiB\n",
      "                  MinMaxScaler:    1.0 KiB\n"
     ]
    }
   ],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tex \n",
    "\\begin{algorithm}\n",
    "\\caption{Preparação de Dados}\n",
    "\\begin{algorithmic}[1]\n",
    "\\Procedure{DataPrep}{$data, column\\_name$}\n",
    "    \\State $MAX\\_LAT \\gets 32.99499999641088$\n",
    "    \\State $MIN\\_LAT \\gets -55.98500000358912$\n",
    "    \\State $MAX\\_LON \\gets -33.009801806103724$\n",
    "    \\State $MIN\\_LON \\gets -119.98980180610373$\n",
    "    \n",
    "    \\State Cria figura com projeção PlateCarree\n",
    "    \\State Restringe coordenadas de acordo com constantes de longitude e latitude\n",
    "\n",
    "    \\State Exibe figura\n",
    "    \n",
    "    \\State $data \\gets$ extrai RGB da figura\n",
    "    \\State $sum\\_channel\\_data \\gets$ soma canais de $data$\n",
    "\n",
    "    \\State \\Return $sum\\_channel\\_data$\n",
    "\\EndProcedure\n",
    "\\end{algorithmic}\n",
    "\\end{algorithm}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
